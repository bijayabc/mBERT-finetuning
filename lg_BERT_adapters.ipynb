{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyOsnkfsHJIjZgAkcV9BvJeF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bijayabc/mBERT-finetuning/blob/main/lg_BERT_adapters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qmCuB2tm82x",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "! pip install watermark transformers datasets lightning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext watermark\n",
        "%watermark --conda -p torch,transformers,datasets,lightning"
      ],
      "metadata": {
        "id": "zXsFaFNeHgPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import lightning as L\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch"
      ],
      "metadata": {
        "id": "bD2hNlmbJj7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load and clean the dataset"
      ],
      "metadata": {
        "id": "K0OoVttsMC6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset('IRIIS-RESEARCH/sentiment-Analysis-Nepali')\n",
        "print(dataset)"
      ],
      "metadata": {
        "id": "EEh75V-6MEqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_raw = dataset['train']\n",
        "split = dataset_raw.train_test_split(test_size=0.2, seed=42)\n",
        "train_dataset_raw = split['train']\n",
        "val_dataset_raw = split['test']\n",
        "test_dataset_raw = dataset['test']"
      ],
      "metadata": {
        "id": "bZdkdx16rYyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenize the dataset"
      ],
      "metadata": {
        "id": "5ABJfe-ZMSEB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the bert tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    texts = [str(t) if t is not None else \"\" for t in examples['sentences']]\n",
        "    return tokenizer(texts, padding='max_length', truncation=True, max_length=128)\n",
        "\n",
        "# Tokenize each split separately\n",
        "train_dataset = train_dataset_raw.map(tokenize_function, batched=True)\n",
        "val_dataset = val_dataset_raw.map(tokenize_function, batched=True)\n",
        "test_dataset = test_dataset_raw.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "id": "zI6pQ2QFMVJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for dataset in [train_dataset, val_dataset, test_dataset]:\n",
        "  dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'sentiment'])"
      ],
      "metadata": {
        "id": "vu6DaKvWN9fg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up Dataloaders"
      ],
      "metadata": {
        "id": "qvlIk66mSJxV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# try using num_workers=2 and see if it is faster\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=12, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, num_workers=12)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, num_workers=12)\n",
        "\n",
        "for batch in train_loader:\n",
        "    input_ids = batch['input_ids']\n",
        "    attention_mask = batch['attention_mask']\n",
        "    labels = batch['sentiment']\n",
        "    # feed these into your model"
      ],
      "metadata": {
        "id": "gGMuRnKiSMJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for dataset in [train_dataset, val_dataset, test_dataset]:\n",
        "  print(len(dataset))"
      ],
      "metadata": {
        "id": "ytPXIhAcqDpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize the Model"
      ],
      "metadata": {
        "id": "r9TkgZFvWhW6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a BERT model for text classification\n",
        "model_name = 'bert-base-multilingual-cased'\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "BpDpSimYWi0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Freeze all layers"
      ],
      "metadata": {
        "id": "BGNv6j6XXFvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "716xSXk2XHMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "JLEJT1cXXWng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"Total trainable parameters: {count_parameters(model):,}\")"
      ],
      "metadata": {
        "id": "WZVPTHuFapyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add Adapter Layers"
      ],
      "metadata": {
        "id": "7_wqyjZ546_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Adapter(nn.Module):\n",
        "  def __init__(self, hidden_size, bottleneck_size=32):\n",
        "    super().__init__()\n",
        "    self.down_proj = nn.Linear(hidden_size, bottleneck_size)\n",
        "    self.activation = nn.GELU()\n",
        "    self.up_proj = nn.Linear(bottleneck_size, hidden_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    down = self.down_proj(x)\n",
        "    activated = self.activation(down)\n",
        "    up = self.up_proj(activated)\n",
        "    return x + up # residual connection"
      ],
      "metadata": {
        "collapsed": true,
        "id": "tUAevA5Y48z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bottleneck_size = 64 # hyperparameter\n",
        "\n",
        "for layer_idx in range(12):\n",
        "    layer = model.bert.encoder.layer[layer_idx]\n",
        "\n",
        "    ##############################################################################\n",
        "    # Wrap the first attention output layer with 1st adapter\n",
        "    ##############################################################################\n",
        "    orig_layer_1 = layer.attention.output.dense # attention output layer\n",
        "    layer.attention.output.dense = nn.Sequential(\n",
        "        orig_layer_1,\n",
        "        Adapter(orig_layer_1.out_features, bottleneck_size)\n",
        "    )\n",
        "\n",
        "    ##############################################################################\n",
        "    # Wrap the output dense layer with 2nd adapter\n",
        "    ##############################################################################\n",
        "    orig_layer_2 = layer.output.dense\n",
        "    layer.output.dense = nn.Sequential(\n",
        "        orig_layer_2,\n",
        "        Adapter(orig_layer_2.out_features, bottleneck_size)\n",
        "    )"
      ],
      "metadata": {
        "id": "pHGmMyGK5bLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "Kn0cTEOWdX2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total number of trainable parameters:\", count_parameters(model))"
      ],
      "metadata": {
        "id": "g4d2uvCodkk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finetuning"
      ],
      "metadata": {
        "id": "6kRz9Kmw9nHh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wrap in LightningModule for training"
      ],
      "metadata": {
        "id": "0gZaaLge9656"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lightning as L\n",
        "import torch\n",
        "import torchmetrics\n",
        "\n",
        "class CustomLightningModule(L.LightningModule):\n",
        "  def __init__(self, model, learning_rate=2e-4, weight_decay=0.01):\n",
        "    super().__init__()\n",
        "    self.model = model\n",
        "    self.learning_rate = learning_rate\n",
        "    self.weight_decay = weight_decay\n",
        "\n",
        "    self.val_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=2)\n",
        "    self.test_acc = torchmetrics.Accuracy(task='multiclass', num_classes=2)\n",
        "\n",
        "  def forward(self, input_ids, attention_mask, labels):\n",
        "    return self.model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    outputs = self(\n",
        "        input_ids=batch[\"input_ids\"],\n",
        "        attention_mask=batch[\"attention_mask\"],\n",
        "        labels=batch[\"sentiment\"]\n",
        "    )\n",
        "    self.log(\"train_loss\", outputs.loss, on_step=False, on_epoch=True, prog_bar=True)\n",
        "    return outputs.loss # This is passed to the optimizer for training\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "    outputs = self(\n",
        "        input_ids=batch[\"input_ids\"],\n",
        "        attention_mask=batch[\"attention_mask\"],\n",
        "        labels=batch[\"sentiment\"]\n",
        "    )\n",
        "    self.log(\"val_loss\", outputs[\"loss\"], on_step=False, on_epoch=True, prog_bar=True)\n",
        "\n",
        "    logits = outputs['logits']\n",
        "    predicted_labels = torch.argmax(logits, dim=1)\n",
        "    self.val_acc(predicted_labels, batch['sentiment'])\n",
        "    self.log('val_acc', self.val_acc, on_step=False, on_epoch=True, prog_bar=True)\n",
        "\n",
        "  def test_step(self, batch, batch_idx):\n",
        "    outputs = self(\n",
        "        input_ids=batch[\"input_ids\"],\n",
        "        attention_mask=batch[\"attention_mask\"],\n",
        "        labels=batch[\"sentiment\"]\n",
        "    )\n",
        "    logits = outputs['logits']\n",
        "    predicted_labels = torch.argmax(logits, dim=1)\n",
        "    self.test_acc(predicted_labels, batch['sentiment'])\n",
        "    self.log('accuracy', self.test_acc, on_step=False, on_epoch=True, prog_bar=True)\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    # optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
        "    optimizer = torch.optim.AdamW(self.parameters(), lr=self.learning_rate, weight_decay=self.weight_decay)\n",
        "    return optimizer\n",
        "\n",
        "lightning_model = CustomLightningModule(model)"
      ],
      "metadata": {
        "id": "XsFXUl-q-A_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from lightning.pytorch.loggers import CSVLogger\n",
        "\n",
        "callbacks = [\n",
        "    ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"max\", monitor=\"val_acc\"\n",
        "    ),  # save top 1 model\n",
        "    EarlyStopping(\n",
        "        monitor=\"val_acc\",\n",
        "        mode=\"max\",\n",
        "        patience=3         # stop if val_acc doesnâ€™t improve after 1 epoch\n",
        "    )\n",
        "]\n",
        "logger = CSVLogger(save_dir='logs/', name='my-model')"
      ],
      "metadata": {
        "id": "9YpFkxTdOxqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = L.Trainer(\n",
        "    max_epochs=20,\n",
        "    callbacks=callbacks,\n",
        "    accelerator=\"gpu\",\n",
        "    precision=\"16-mixed\",\n",
        "    devices=[0],\n",
        "    logger=logger,\n",
        "    log_every_n_steps=10,\n",
        "    gradient_clip_val=1.0,\n",
        ")"
      ],
      "metadata": {
        "id": "LeDecAkTNjvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start = time.time()\n",
        "\n",
        "trainer.fit(model=lightning_model,\n",
        "            train_dataloaders=train_loader,\n",
        "            val_dataloaders=val_loader)\n",
        "\n",
        "end = time.time()\n",
        "elapsed = end - start\n",
        "print(f'time elapsed: {elapsed/60:.2f} min')"
      ],
      "metadata": {
        "id": "IJ6dsyHyONos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.test(lightning_model, dataloaders=train_loader, ckpt_path=\"best\")"
      ],
      "metadata": {
        "id": "o6T1iaDcOpbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "trainer.test(lightning_model, dataloaders=val_loader, ckpt_path=\"best\")"
      ],
      "metadata": {
        "id": "9Jx3QPoIOrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.test(model=lightning_model, dataloaders=test_loader, ckpt_path=None)"
      ],
      "metadata": {
        "id": "It3rNoL4VMni"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}